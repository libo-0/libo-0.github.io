---
title: Kafka-概览-生产者
tags:
  - Kafka
categories:
  - Kafka
date: 2020-03-06 14:50:05
img: /images/hintersee.jpg
---


<!-- more -->

## 构造一个 Kafka Producer

写消息到 Kafka 的第一步是创建一个生产者对象。一个 Kafka 生产者必须包含这三个属性：

* bootstrap.servers

生产者用来建立到 Kafka 簇的初始连接的 broker 列表，host:port 形式。

* key.serializer

生产到 Kafka 的用来序列化记录的 key 的类。Kafka broker 期待 byte array 类型的 key 和 value 消息。

* value.serializer

```Java
private Properties kafkaProps = new Properties(); kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");
kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); 
producer = new KafkaProducer<String, String>(kafkaProps);
```

## 发送消息的 3 种主要方法

* Fire and forget
* Synchronous send
* Asynchronous send

## 发送消息到 Kafka

```Java
ProducerRecord<String, String> record =
            new ProducerRecord<>("CustomerCountry", "Precision Products","France");
try { producer.send(record);
} catch (Exception e) { e.printStackTrace();
}
```

生产者接受 `ProducerRecord` 对象，这个消息被放入一个 buffer，在一个单独的线程中被发送到 broker，send()方法返回一个 Java Future object：`RecordMetadata`。

## Sending a Message Synchronously

```Java
ProducerRecord<String, String> record =
            new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
producer.send(record).get();
    } catch (Exception e) {
e.printStackTrace();
}
```

使用 `Future.get()` 来等待 Kafka 的回复。没有发送成功抛异常；没有错误会获得一个 RecordMetadata 对象。

## Sending a Message Asynchronously

```Java
private class DemoProducerCallback implements Callback {
    @Override
    public void onCompletion(RecordMetadata recordMetadata, Exception e) {
         if (e != null) {
            e.printStackTrace(); }
} }
ProducerRecord<String, String> record =
            new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA");
producer.send(record, new DemoProducerCallback());
```

为了使用回调，需要实现 `org.apache.kafka. clients.producer.Callback` 接口，有一个 `onCompletion()` 方法。

## Configuring Producers

Producer 有很多配置参数；大多数在 Apache Kafka 文件中有默认的值。一些参数对内存使用，性能，生产者的可靠性有很大影响。

### acks

acks 参数控制有多少个分区复制必须接收到这条记录，生产者才会认为是一次写成功。这个参数对消息的几率有很大影响。acks 有3 个允许的值。

* acks = 0，生产者不会等待 broker 认为消息发送成功的回复。虽然生产者不知道消息是否发送成功或丢失，但是可以用最快的网络发送消息，因此可以有较高的吞吐量。

* acks = 1， 生产者会接收到 broker 的 leader replica 的接收成功回复。如果消息不能写到 leader，producer 会接收到错误信息，并重试发送。取决于发送信息是同步还是异步，会影响延迟或吞吐量。

* acks=all， broker 的所有同步 replicas 接收到消息后，生产者才会接收到成功的响应。这是最安全的设置，因为你可以确保超过 1个 broker 接收到这个消息，及时崩溃，消息也会存活。然而延迟会更高。

### buffer.memory

这回设置生产者在发送消息到 broker 之前的缓存消息的 buffer 大小。

### compress.type

默认，消息发送不被压缩。这个参数可以是：snappy, gzip, lz4。snappy 压缩由 Google 发明，提供令人满意的压缩率，较低的 CPU 花费，并且有不错的性能，所以推荐在性能和带宽作为关注点时使用。Gzip 使用更多的 CPU，但是有更高的压缩比，推荐在网络带宽被限制时使用。通过启用压缩，减少了网络利用和存储，这通常是 Kafka 发送信息的瓶颈。

### retries

当生产者从服务器收到一个错误信息时，错误可能是短暂的（分区 leader 缺失）。这种情况，重试参数的默认值决定了生产者在放弃发送消息并通知客户端发生了一个问题之前，重试发送多少次。默认，生产者会在重试之间间隔 100 ms，但是你能够使用 retry.backoff.ms 来控制。

### batch.size

当多条记录发送到相同的分区时，生产者会将他们打包成一批。这将被用来控制 每个 batch 在内存中以 byte 为单位的大小。当 batch 满了以后，所有在 batch 中的消息将被发送。然而，producer 不会等到 batch 满了以后才会发送。producer 会发送
half-full batch 大小，甚至是只包含一条消息。因此，设置 batch 太大会不会造成延迟；只是 batch 会用更多的内存。设置太小，会给系统添加负担，因为生唱着发送的太频繁。

### linger.ms

控制在下一条消息到来前多久等待多久开始发送 batch

### client.id

任意字符串，被 broker 标识消息来源，用于日志，metrics。

### max.in.flight.requests.per.connection

### timeout.ms, request.timeout.ms, metadata.fetch.timeout.ms

### max.block.ms

### max.request.size

### receive.buffer.bytes and send.buffer.bytes

## 分区

相同 key 的 消息会被写到相同分区。

创建 key-value 记录

```Java
ProducerRecord<Integer, String> record =
            new ProducerRecord<>("CustomerCountry", "Laboratory Equipment", "USA");
```

创建 key 为 null 记录

```Java
 ProducerRecord<Integer, String> record =
            new ProducerRecord<>("CustomerCountry", "USA");

```